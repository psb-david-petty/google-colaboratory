{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/psb-david-petty/google-colaboratory/blob/master/wordle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX1wKx7cjna4"
      },
      "source": [
        "# `wordle.py`\n",
        "\n",
        "[WORDLE](https://powerlanguage.co.uk/wordle/) is '...a daily word game.'\n",
        "\n",
        "> I originally downloaded word-lists I found on-line (starting with OWL3) for use in this project, but by [open-sourcing](https://bigtechquestion.com/2019/03/07/software/windows/what-does-open-sourcing-mean/) this tool, I would also have to publish the word-lists. To avoid that, I added `wordset.py` to read the word-list files from URIs (either as raw `.txt` files or from [`.zip`](https://docs.python.org/3/library/zipfile.html) files).\n",
        "\n",
        "## The word-lists\n",
        "\n",
        "| Source | Link | Description |\n",
        "| --- | --- | --- |\n",
        "| [dolph](https://github.com/dolph/dictionary) | [https://raw.githubusercontent.com/dolph/dictionary/master/enable1.txt](https://raw.githubusercontent.com/dolph/dictionary/master/enable1.txt) | [TK]([https://en.wikipedia.org/wiki/To_come_(publishing) |\n",
        "| [dolph](https://github.com/dolph/dictionary) | [https://raw.githubusercontent.com/dolph/dictionary/master/ospd.txt](https://raw.githubusercontent.com/dolph/dictionary/master/ospd.txt) | [TK]([https://en.wikipedia.org/wiki/To_come_(publishing) |\n",
        "| [dolph](https://github.com/dolph/dictionary) | [https://raw.githubusercontent.com/dolph/dictionary/master/popular.txt](https://raw.githubusercontent.com/dolph/dictionary/master/popular.txt) | [TK]([https://en.wikipedia.org/wiki/To_come_(publishing) |\n",
        "| [dolph](https://github.com/dolph/dictionary) | [https://raw.githubusercontent.com/dolph/dictionary/master/unix-words](https://raw.githubusercontent.com/dolph/dictionary/master/unix-words) | [TK]([https://en.wikipedia.org/wiki/To_come_(publishing) |\n",
        "| [WordGameDictionary](https://www.wordgamedictionary.com/word-lists/) | [https://www.wordgamedictionary.com/english-word-list/download/english.txt](https://www.wordgamedictionary.com/english-word-list/download/english.txt) | [TK]([https://en.wikipedia.org/wiki/To_come_(publishing) |\n",
        "| [WordGameDictionary](https://www.wordgamedictionary.com/word-lists/) | [https://www.wordgamedictionary.com/sowpods/download/sowpods.txt](https://www.wordgamedictionary.com/sowpods/download/sowpods.txt) | [TK]([https://en.wikipedia.org/wiki/To_come_(publishing) |\n",
        "| [WordGameDictionary](https://www.wordgamedictionary.com/word-lists/) | [https://www.wordgamedictionary.com/twl06/download/twl06.txt](https://www.wordgamedictionary.com/twl06/download/twl06.txt) | [TK]([https://en.wikipedia.org/wiki/To_come_(publishing) |\n",
        "| [yawl](https://github.com/elasticdog/yawl) | [https://raw.githubusercontent.com/elasticdog/yawl/master/yawl-0.3.2.03.tar.gz](https://raw.githubusercontent.com/elasticdog/yawl/master/yawl-0.3.2.03.tar.gz) | `yawl-0.3.2.03/sigword.list` |\n",
        "| [yawl](https://github.com/elasticdog/yawl) | [https://raw.githubusercontent.com/elasticdog/yawl/master/yawl-0.3.2.03.tar.gz](https://raw.githubusercontent.com/elasticdog/yawl/master/yawl-0.3.2.03.tar.gz) | `yawl-0.3.2.03/word.list` |\n",
        "| [SDSawtelle](https://sdsawtelle.github.io/blog/output/scrabble-cheatsheet-with-python.html) | [https://sdsawtelle.github.io/blog/output/scrabble-cheatsheet-with-python.html](https://sdsawtelle.github.io/blog/output/scrabble-cheatsheet-with-python.html) | Python cannot directly extract `OWL3_Dictionary.7z` without additional libraries |\n",
        "\n",
        "\n",
        "## Other enhancements\n",
        "\n",
        "- I made this a command-line tool using [`optparse`](https://docs.python.org/3/library/optparse.html). (TODO: update to use [`argparse`](https://docs.python.org/3/library/argparse.html).) The command-line help is:\n",
        "\n",
        "```\n",
        "Usage: spellingbee.py {LETTERS | -i} [-l L] [-? -v]\n",
        "\n",
        "Find spelling-bee words using LETTERS and including LETTERS[0].\n",
        "\n",
        "Options:\n",
        "  --version         show program's version number and exit\n",
        "  -?, --help        show this help message and exit\n",
        "  -i, --input       input LETTERS from keyboard? [False]\n",
        "  -l L, --length=L  words of length >= L [5]\n",
        "  -v, --verbose     log status information while processing [False]\n",
        "```\n",
        "- Added [`logging`](https://docs.python.org/3/howto/logging.html).\n",
        "- This [`Colab Notebook`](https://github.com/psb-david-petty/google-colaboratory/blob/master/spellingbee.ipynb) was originally developed from a multi-file module &mdash; which required adapting some code and changing some [`import`](https://docs.python.org/3/reference/import.html) statements.\n",
        "- The biggest addition was reading the word-lists on line from URIs, rather than publishing the word-lists myself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9DngRv5iYDZ",
        "outputId": "87f74f3f-2f1f-4643-b098-4def22675a7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022/08/01-17:18:07  __main__  INFO     I: SPAM, SPAM\n",
            "2022/08/01-17:18:07  __main__  WARNING  W: SPAM, SPAM, SPAM\n",
            "2022/08/01-17:18:07  __main__  ERROR    E: SPAM, SPAM, SPAM, SPAM\n",
            "2022/08/01-17:18:07  __main__  CRITICAL C: SPAM, SPAM, SPAM, SPAM, SPAM\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "#\n",
        "# log.py\n",
        "#\n",
        "import logging, tempfile\n",
        "\n",
        "1234567890123456789012345678901234567890123456789012345678901234567890\n",
        "\"\"\"\n",
        "Logging module that logs to the console and a temporary log file.\n",
        "\"\"\"\n",
        "__all__ = [\"log\", \"log_path\", ]\n",
        "__author__ = \"David C. Petty\"\n",
        "__copyright__ = \"Copyright 2022, David C. Petty\"\n",
        "__license__ = \"https://choosealicense.com/licenses/mit/\"\n",
        "__version__ = \"0.0.1\"\n",
        "__maintainer__ = \"David C. Petty\"\n",
        "__email__ = \"david_petty@psbma.org\"\n",
        "__status__ = \"Development\"\n",
        "\n",
        "path = globals().get('path')    # Initialize global path to temporary log.\n",
        "\n",
        "\n",
        "def log(name, level=logging.INFO):\n",
        "    \"\"\"Return logger with name and level.\"\"\"\n",
        "    global path\n",
        "    new_file = path is None\n",
        "\n",
        "    # If name already has a logger, return it.\n",
        "    if name in logging.root.manager.loggerDict:\n",
        "        return logging.getLogger(name)\n",
        "\n",
        "    FORMAT = '{asctime:s} {name:^10s} ' \\\n",
        "             '[{threadName:^10s}] {levelname:<8s} {message:s}'\n",
        "    FORMAT = '{asctime:s} {name:^10s} {levelname:<8s} {message:s}'\n",
        "    logging.basicConfig(filename='/dev/null', level=logging.NOTSET)\n",
        "    logger = logging.getLogger(name)\n",
        "\n",
        "    # Create file handler which logs messages at level.\n",
        "    if new_file:\n",
        "        fd, path = tempfile.mkstemp('.log', 'wordle-')\n",
        "    fh = logging.FileHandler(path, 'a')\n",
        "    fh.setLevel(level)\n",
        "\n",
        "    # Create console handler which logs messages at level.\n",
        "    ch = logging.StreamHandler()\n",
        "    ch.setLevel(level)\n",
        "\n",
        "    # Create formatter and add it to handlers.\n",
        "    formatter = logging.Formatter(\n",
        "        FORMAT, style='{', datefmt='%Y/%m/%d-%H:%M:%S')\n",
        "    ch.setFormatter(formatter)\n",
        "    fh.setFormatter(formatter)\n",
        "\n",
        "    # Add the handlers to logger.\n",
        "    logger.addHandler(ch)\n",
        "    logger.addHandler(fh)\n",
        "\n",
        "    return logger\n",
        "\n",
        "\n",
        "def log_path():\n",
        "    \"\"\"Return path for temporary log file.\"\"\"\n",
        "    global path\n",
        "    return path\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    logger = log(__name__)\n",
        "    logger.debug('D: SPAM')\n",
        "    logging.debug('D: SPAM')\n",
        "    logger.info('I: SPAM, SPAM')\n",
        "    logger.warning('W: SPAM, SPAM, SPAM')\n",
        "    logger.error('E: SPAM, SPAM, SPAM, SPAM')\n",
        "    logger.critical('C: SPAM, SPAM, SPAM, SPAM, SPAM')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jCSZ8c9BijJ5"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin.env python3\n",
        "#\n",
        "# word.py\n",
        "#\n",
        "import string\n",
        "\n",
        "1234567890123456789012345678901234567890123456789012345678901234567890\n",
        "\"\"\"\n",
        "Letter utilities for solving NYTimes Spelling Bee puzzle.\n",
        "\"\"\"\n",
        "__all__ = [\"hasonly\", \"musthave\", \"is_valid\", ]\n",
        "__author__ = \"David C. Petty\"\n",
        "__copyright__ = \"Copyright 2016-2021, David C. Petty\"\n",
        "__license__ = \"https://choosealicense.com/licenses/mit/\"\n",
        "__version__ = \"0.0.1\"\n",
        "__maintainer__ = \"David C. Petty\"\n",
        "__email__ = \"david_petty@psbma.org\"\n",
        "__status__ = \"Development\"\n",
        "\n",
        "\n",
        "def hasonly(word, letters):\n",
        "    \"\"\"Return True if elements of word are only in letters, otherwise False.\"\"\"\n",
        "    letterset = set(letters)\n",
        "    return letterset.union(set(word)) == letterset\n",
        "\n",
        "\n",
        "def hasnone(word, letters):\n",
        "    \"\"\"Return True if elements of word are not in letters, otherwise False.\"\"\"\n",
        "    letterset = set(letters)\n",
        "    return letterset.intersection(set(word)) == set()\n",
        "\n",
        "\n",
        "def musthave(word, letters):\n",
        "    \"\"\"Return True if elements of letters are all in word, otherwise False.\"\"\"\n",
        "    letterset = set(letters)\n",
        "    return letterset.intersection(set(word)) == letterset\n",
        "\n",
        "\n",
        "# Return True if w is a (hyphenated) word that is all one case, False otherwise.\n",
        "is_valid = lambda w: w and hasonly(w, string.ascii_letters + '-') \\\n",
        "    and (w == w.lower() or w == w.upper())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rvVGP0fEisto"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin.env python3\n",
        "#\n",
        "# wordset.py\n",
        "#\n",
        "import os.path\n",
        "# from log import log\n",
        "# from word import is_valid\n",
        "\n",
        "1234567890123456789012345678901234567890123456789012345678901234567890\n",
        "\"\"\"\n",
        "Functions to read wordlists from file or URI and parse them into sets.\n",
        "\"\"\"\n",
        "__all__ = [\"wordsites\", \"wordfiles\", ]\n",
        "__author__ = \"David C. Petty\"\n",
        "__copyright__ = \"Copyright 2016-2021, David C. Petty\"\n",
        "__license__ = \"https://choosealicense.com/licenses/mit/\"\n",
        "__version__ = \"0.0.1\"\n",
        "__maintainer__ = \"David C. Petty\"\n",
        "__email__ = \"david_petty@psbma.org\"\n",
        "__status__ = \"Development\"\n",
        "\n",
        "logger = log(__name__)  # initialize logger\n",
        "\n",
        "\n",
        "# https://stackoverflow.com/a/5711095\n",
        "import io, gzip, tarfile, zipfile\n",
        "from urllib.request import urlopen\n",
        "\n",
        "# https://docs.python-requests.org/en/master/\n",
        "# or: requests.get(url).content\n",
        "\n",
        "# https://docs.python.org/3/library/zipfile.html\n",
        "# zipfile = ZipFile(io.BytesIO(resp.read()))\n",
        "# names = zipfile.namelist()\n",
        "# for name in names:\n",
        "#     for line in zipfile.open(name).readlines():\n",
        "#         print(line.decode('utf-8'))\n",
        "\n",
        "# https://stackoverflow.com/a/49174340\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "format = lambda k, w: f\"{k}({len(w)}): {sorted(list(w))[: 10]} ...\"\n",
        "\n",
        "def txtwordset(uri, verbose=False):\n",
        "    \"\"\"Return set of words parsed from raw URI. Echo results if verbose.\"\"\"\n",
        "    name = os.path.basename(urlparse(uri).path)\n",
        "    with urlopen(uri) as resp:\n",
        "        wordset = {w.lower() for w in\n",
        "            [line.decode('utf-8').strip() for line in resp.readlines()]\n",
        "                if is_valid(w)}\n",
        "        logger.info(format(name, wordset))\n",
        "        return wordset\n",
        "\n",
        "def zipwordsets(uri, names, wordssets, verbose=False):\n",
        "    \"\"\"\"\"\"\n",
        "    with urlopen(uri) as resp:\n",
        "        with tarfile.open(fileobj=io.BytesIO(resp.read()), mode='r:gz') as tar:\n",
        "            zipname = os.path.basename(urlparse(uri).path)\n",
        "            if verbose: logger.info(f\"{zipname}: {tar.getnames()}\")\n",
        "            for path in names:\n",
        "                name = os.path.basename(path)\n",
        "                wordset = {w.lower() for w in\n",
        "                           [line.decode('utf-8').strip() for line in\n",
        "                        tar.extractfile(path).readlines()]\n",
        "                           if is_valid(w)}\n",
        "                logger.info(format(name, wordset))\n",
        "                wordssets[name] = wordset\n",
        "\n",
        "log_site = lambda s: logger.info(f\"{'#' * 10} SITE: {s}\")\n",
        "\n",
        "def wordssites(verbose=False):\n",
        "    \"\"\"Return list of sets of words from:\n",
        "    URI: https://raw.githubusercontent.com/dolph/dictionary/master/enable1.txt\n",
        "    URI: https://raw.githubusercontent.com/dolph/dictionary/master/ospd.txt\n",
        "    URI: https://raw.githubusercontent.com/dolph/dictionary/master/popular.txt\n",
        "    URI: https://raw.githubusercontent.com/dolph/dictionary/master/unix-words\n",
        "    URI: https://www.wordgamedictionary.com/english-word-list/download/english.txt\n",
        "    URI: https://www.wordgamedictionary.com/sowpods/download/sowpods.txt\n",
        "    URI: https://www.wordgamedictionary.com/twl06/download/twl06.txt\n",
        "    URI: https://raw.githubusercontent.com/elasticdog/yawl/master/yawl-0.3.2.03.tar.gz yawl-0.3.2.03/sigword.list\n",
        "    URI: https://raw.githubusercontent.com/elasticdog/yawl/master/yawl-0.3.2.03.tar.gz yawl-0.3.2.03/word.list\n",
        "    URI: https://sdsawtelle.github.io/blog/output/scrabble-cheatsheet-with-python.html # cannot directly extract OWL3_Dictionary.7z\n",
        "    \"\"\"\n",
        "    wordssets = dict()\n",
        "\n",
        "    # Read word-lists from dolph URIs.\n",
        "    log_site('dolph')\n",
        "    for uri in [\n",
        "        #'https://raw.githubusercontent.com/dolph/dictionary/master/enable1.txt',\n",
        "        'https://raw.githubusercontent.com/dolph/dictionary/master/ospd.txt',\n",
        "        #'https://raw.githubusercontent.com/dolph/dictionary/master/popular.txt',\n",
        "        #'https://raw.githubusercontent.com/dolph/dictionary/master/unix-words',\n",
        "    ]:\n",
        "        key = os.path.basename(urlparse(uri).path)\n",
        "        wordssets[key] = txtwordset(uri, verbose)\n",
        "    \"\"\"\n",
        "    # Read word-lists from wordgamedictionary URIs.\n",
        "    log_site('wordgamedictionary')\n",
        "    for uri in [\n",
        "        'https://www.wordgamedictionary.com/english-word-list/download/english.txt',\n",
        "        'https://www.wordgamedictionary.com/sowpods/download/sowpods.txt',\n",
        "        'https://www.wordgamedictionary.com/twl06/download/twl06.txt',\n",
        "    ]:\n",
        "        key = os.path.basename(urlparse(uri).path)\n",
        "        wordssets[key] = txtwordset(uri, verbose)\n",
        "\n",
        "    # Read word-lists from elasticdog URIs.\n",
        "    log_site('elasticdog')\n",
        "    uri = 'https://raw.githubusercontent.com/elasticdog/yawl/master/yawl-0.3.2.03.tar.gz'\n",
        "    keys = ['yawl-0.3.2.03/word.list', 'yawl-0.3.2.03/sigword.list', ]\n",
        "    zipwordsets(uri, keys, wordssets, verbose)\n",
        "    \"\"\"\n",
        "    return wordssets\n",
        "\n",
        "\n",
        "def wordsfiles(wordsdir=os.path.dirname(os.path.abspath(globals().get('__file__', ''))),\n",
        "      wordsfiles=[\n",
        "          'enable1.txt', 'ospd.txt', 'popular.txt', 'unix-words',\n",
        "          'english.txt', 'sowpods.txt', 'twl06.txt',\n",
        "          'sigword.list', 'word.list',\n",
        "          'OWL3_Dictionary.txt',\n",
        "      ], verbose=False):\n",
        "    \"\"\"\"\"\"\n",
        "    # Read word-list files from local directory into dictionary of word-sets.\n",
        "    wordssets = dict()\n",
        "    for wordsname in wordsfiles:\n",
        "        logger.info(f\"NAME: {wordsname}\")\n",
        "        with open(os.path.join(wordsdir, wordsname), 'r') as wordsfile:\n",
        "            wordssets[wordsname] = {w.lower() for w in wordsfile.read().split('\\n')\n",
        "                if is_valid(w)}\n",
        "\n",
        "    return wordssets\n",
        "\n",
        "import functools, sortedcontainers\n",
        "@functools.lru_cache(1)\n",
        "def words_as_sets(length=5):\n",
        "    \"\"\"Return set of words of length length as sorted sets.\"\"\"\n",
        "    wordsdict = wordssites()\n",
        "    words = set.union(*wordsdict.values())\n",
        "    return tuple(tuple(w.upper()) for w in words if len(w) == length )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgLVvqKyjy0z",
        "outputId": "64a05f88-a24f-468d-bd30-cbf9df368ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022/08/01-17:18:08  __main__  INFO     python3 /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -v NOTHING\n",
            "2022/08/01-17:18:08  __main__  INFO     LOG PATH: /tmp/wordle-soobzve3.log\n",
            "2022/08/01-17:18:08  __main__  INFO     ########## SITE: dolph\n",
            "2022/08/01-17:18:09  __main__  INFO     ospd.txt(79339): ['aa', 'aah', 'aahed', 'aahing', 'aahs', 'aal', 'aalii', 'aaliis', 'aals', 'aardvark'] ...\n",
            "2022/08/01-17:18:09  __main__  INFO     252 combinations of 5 letters out of the 10 most common: 'ETAOINSHRD'... (~3s)\n",
            "2022/08/01-17:18:11  __main__  INFO     groups with words: (ADEHR,ADEHS,ADEHT,ADEIR,ADEIS,ADENO,ADENR,ADENS,ADENT,ADEOR,ADERS,ADERT,ADEST,ADHIS,ADHNO,ADHNS,ADHOR,ADHRS,ADHST,ADINO,ADINR,ADIOR,ADIOS,ADIRS,ADIRT,ADIST,ADNOR,ADNOS,ADNRS,ADNST,ADORS,ADORT,ADOST,ADRST,AEHNS,AEHNT,AEHRS,AEHRT,AEHST,AEINS,AEINT,AEIRS,AEIRT,AENOS,AENOT,AENRS,AENRT,AENST,AEORS,AEORT,AEOST,AERST,AHIOS,AHIRS,AHIRT,AHIST,AHNRS,AHNST,AHORS,AHORT,AHOST,AHRST,AINOR,AINRS,AINRT,AINST,AIORT,AIOST,AIRST,ANORS,ANORT,ANRST,AORST,DEHIR,DEHIS,DEHNO,DEHNS,DEHOR,DEHOS,DEHOT,DEHRS,DEINR,DEINS,DEINT,DEIOS,DEIRS,DEIRT,DEIST,DENOR,DENOS,DENOT,DENRS,DENRT,DENST,DEORS,DEORT,DEOST,DERST,DHINS,DHIOT,DHIRT,DINOT,DINRS,DINST,DIORT,DIOST,DIRST,EHINS,EHINT,EHIOS,EHIRS,EHIRT,EHIST,EHNOR,EHNOS,EHNRS,EHNST,EHORS,EHORT,EHOST,EINOR,EINOS,EINRS,EINRT,EINST,EIORS,EIRST,ENORS,ENORT,ENOST,ENRST,EORST,HINOR,HINST,HIOST,HIRST,HNORS,HNORT,HORST,INORS,INORT,IORST,NORST)\n",
            "2022/08/01-17:18:11  __main__  INFO     time: 2.4s\n",
            "2022/08/01-17:18:11  __main__  INFO     10153 combinations of 2 group(s) out of the 143 with words... (~0s)\n",
            "2022/08/01-17:18:11  __main__  INFO     time: 0.0s\n",
            "2022/08/01-17:18:11  __main__  INFO     143 groups with words; 37 guesses of length 2;\n",
            "2022/08/01-17:18:11  __main__  INFO     words: 143 (first 143)\n",
            "2022/08/01-17:18:11  __main__  INFO     ADEHR: ('HARED', 'HEARD')\n",
            "2022/08/01-17:18:11  __main__  INFO     ADEHS: ('ASHED', 'DEASH', 'HADES', 'HEADS', 'SADHE', 'SHADE')\n",
            "2022/08/01-17:18:11  __main__  INFO     ADEHT: ('DEATH', 'HATED')\n",
            "2022/08/01-17:18:11  __main__  INFO     ADEIR: ('AIDER', 'AIRED', 'DEAIR', 'IRADE', 'REDIA')\n",
            "2022/08/01-17:18:11  __main__  INFO     ADEIS: ('AIDES', 'ASIDE', 'IDEAS')\n",
            "2022/08/01-17:18:11  __main__  INFO     ADENO: ('ANODE',)\n",
            "2022/08/01-17:18:11  __main__  INFO     ADENR: ('REDAN',)\n",
            "2022/08/01-17:18:11  __main__  INFO     ADENS: ('DEANS', 'SANED', 'SEDAN')\n",
            "2022/08/01-17:18:11  __main__  INFO     ADENT: ('ANTED',)\n",
            "2022/08/01-17:18:11  __main__  INFO     ADEOR: ('ADORE', 'OARED', 'OREAD')\n",
            "2022/08/01-17:18:11  __main__  INFO     ADERS: ('DARES', 'DEARS', 'RASED', 'READS')\n",
            "2022/08/01-17:18:11  __main__  INFO     ADERT: ('DATER', 'DERAT', 'RATED', 'TARED', 'TRADE', 'TREAD')\n",
            "2022/08/01-17:18:11  __main__  INFO     ADEST: ('DATES', 'SATED', 'STADE', 'STEAD', 'TSADE')\n",
            "2022/08/01-17:18:11  __main__  INFO     ADHIS: ('DASHI',)\n",
            "2022/08/01-17:18:11  __main__  INFO     ADHNO: ('HONDA',)\n",
            "2022/08/01-17:18:11  __main__  INFO     ADHNS: ('HANDS',)\n",
            "2022/08/01-17:18:11  __main__  INFO     ADHOR: ('HOARD',)\n",
            "2022/08/01-17:18:11  __main__  INFO     ADHRS: ('HARDS', 'SHARD')\n",
            "2022/08/01-17:18:11  __main__  INFO     ADHST: ('HADST',)\n",
            "2022/08/01-17:18:11  __main__  INFO     ADINO: ('DANIO',)\n",
            "2022/08/01-17:18:11  __main__  INFO     ADINR: ('DINAR', 'DRAIN', 'NADIR', 'RANID')\n",
            "2022/08/01-17:18:11  __main__  INFO     ADIOR: ('AROID', 'RADIO')\n",
            "2022/08/01-17:18:11  __main__  INFO     ADIOS: ('ADIOS',)\n",
            "2022/08/01-17:18:11  __main__  INFO     ADIRS: ('RAIDS',)\n",
            "2022/08/01-17:18:11  __main__  INFO     ADIRT: ('TRIAD',)\n",
            "2022/08/01-17:18:11  __main__  INFO     ADIST: ('ADITS', 'DITAS', 'STAID', 'TSADI')\n",
            "2022/08/01-17:18:11  __main__  INFO     ADNOR: ('ADORN', 'RADON')\n",
            "2022/08/01-17:18:11  __main__  INFO     ADNOS: ('DONAS',)\n",
            "2022/08/01-17:18:11  __main__  INFO     ADNRS: ('DARNS', 'NARDS', 'RANDS')\n",
            "2022/08/01-17:18:11  __main__  INFO     ADNST: ('STAND',)\n",
            "2022/08/01-17:18:11  __main__  INFO     ADORS: ('DORSA', 'ROADS', 'SAROD')\n",
            "2022/08/01-17:18:11  __main__  INFO     ADORT: ('TARDO',)\n",
            "2022/08/01-17:18:11  __main__  INFO     ADOST: ('DATOS', 'DOATS', 'TOADS')\n",
            "2022/08/01-17:18:11  __main__  INFO     ADRST: ('DARTS', 'DRATS')\n",
            "2022/08/01-17:18:11  __main__  INFO     AEHNS: ('ASHEN', 'HANSE')\n",
            "2022/08/01-17:18:11  __main__  INFO     AEHNT: ('NEATH', 'THANE')\n",
            "2022/08/01-17:18:11  __main__  INFO     AEHRS: ('HARES', 'HEARS', 'RHEAS', 'SHARE', 'SHEAR')\n",
            "2022/08/01-17:18:11  __main__  INFO     AEHRT: ('EARTH', 'HATER', 'HEART', 'RATHE')\n",
            "2022/08/01-17:18:11  __main__  INFO     AEHST: ('HAETS', 'HASTE', 'HATES', 'HEATS')\n",
            "2022/08/01-17:18:11  __main__  INFO     AEINS: ('ANISE',)\n",
            "2022/08/01-17:18:11  __main__  INFO     AEINT: ('ENTIA', 'TENIA', 'TINEA')\n",
            "2022/08/01-17:18:11  __main__  INFO     AEIRS: ('ARISE', 'RAISE', 'SERAI')\n",
            "2022/08/01-17:18:11  __main__  INFO     AEIRT: ('IRATE', 'RETIA', 'TERAI')\n",
            "2022/08/01-17:18:11  __main__  INFO     AENOS: ('AEONS',)\n",
            "2022/08/01-17:18:11  __main__  INFO     AENOT: ('ATONE', 'OATEN')\n",
            "2022/08/01-17:18:11  __main__  INFO     AENRS: ('EARNS', 'NARES', 'NEARS', 'SANER', 'SNARE')\n",
            "2022/08/01-17:18:11  __main__  INFO     AENRT: ('ANTRE',)\n",
            "2022/08/01-17:18:11  __main__  INFO     AENST: ('ANTES', 'ETNAS', 'NATES', 'NEATS', 'STANE')\n",
            "2022/08/01-17:18:11  __main__  INFO     AEORS: ('AROSE',)\n",
            "2022/08/01-17:18:11  __main__  INFO     AEORT: ('OATER', 'ORATE')\n",
            "2022/08/01-17:18:11  __main__  INFO     AEOST: ('STOAE',)\n",
            "2022/08/01-17:18:11  __main__  INFO     AERST: ('ASTER', 'RATES', 'STARE', 'TARES', 'TEARS')\n",
            "2022/08/01-17:18:11  __main__  INFO     AHIOS: ('OHIAS',)\n",
            "2022/08/01-17:18:11  __main__  INFO     AHIRS: ('HAIRS',)\n",
            "2022/08/01-17:18:11  __main__  INFO     AHIRT: ('AIRTH',)\n",
            "2022/08/01-17:18:11  __main__  INFO     AHIST: ('SAITH',)\n",
            "2022/08/01-17:18:11  __main__  INFO     AHNRS: ('SHARN',)\n",
            "2022/08/01-17:18:11  __main__  INFO     AHNST: ('HANTS', 'SNATH')\n",
            "2022/08/01-17:18:11  __main__  INFO     AHORS: ('HOARS', 'HORAS')\n",
            "2022/08/01-17:18:11  __main__  INFO     AHORT: ('TORAH',)\n",
            "2022/08/01-17:18:11  __main__  INFO     AHOST: ('HOSTA', 'OATHS', 'SHOAT')\n",
            "2022/08/01-17:18:11  __main__  INFO     AHRST: ('HARTS', 'TAHRS', 'TRASH')\n",
            "2022/08/01-17:18:11  __main__  INFO     AINOR: ('NORIA',)\n",
            "2022/08/01-17:18:11  __main__  INFO     AINRS: ('AIRNS', 'NARIS', 'RAINS', 'RANIS', 'SARIN')\n",
            "2022/08/01-17:18:11  __main__  INFO     AINRT: ('RIANT', 'TRAIN')\n",
            "2022/08/01-17:18:11  __main__  INFO     AINST: ('ANTIS', 'SAINT', 'SATIN', 'STAIN', 'TAINS')\n",
            "2022/08/01-17:18:11  __main__  INFO     AIORT: ('RATIO',)\n",
            "2022/08/01-17:18:11  __main__  INFO     AIOST: ('IOTAS', 'OSTIA', 'STOAI')\n",
            "2022/08/01-17:18:11  __main__  INFO     AIRST: ('AIRTS', 'ASTIR', 'SITAR', 'STAIR', 'STRIA', 'TARSI')\n",
            "2022/08/01-17:18:11  __main__  INFO     ANORS: ('ARSON', 'ROANS', 'SONAR')\n",
            "2022/08/01-17:18:11  __main__  INFO     ANORT: ('TRONA',)\n",
            "2022/08/01-17:18:11  __main__  INFO     ANRST: ('RANTS', 'TARNS', 'TRANS')\n",
            "2022/08/01-17:18:11  __main__  INFO     AORST: ('RATOS', 'ROAST', 'ROTAS', 'TAROS', 'TORAS')\n",
            "2022/08/01-17:18:11  __main__  INFO     DEHIR: ('HIDER', 'HIRED')\n",
            "2022/08/01-17:18:11  __main__  INFO     DEHIS: ('HIDES', 'SHIED')\n",
            "2022/08/01-17:18:11  __main__  INFO     DEHNO: ('HONED',)\n",
            "2022/08/01-17:18:11  __main__  INFO     DEHNS: ('SHEND',)\n",
            "2022/08/01-17:18:11  __main__  INFO     DEHOR: ('HORDE',)\n",
            "2022/08/01-17:18:11  __main__  INFO     DEHOS: ('HOSED', 'SHOED')\n",
            "2022/08/01-17:18:11  __main__  INFO     DEHOT: ('DOETH',)\n",
            "2022/08/01-17:18:11  __main__  INFO     DEHRS: ('HERDS', 'SHERD', 'SHRED')\n",
            "2022/08/01-17:18:11  __main__  INFO     DEINR: ('DINER',)\n",
            "2022/08/01-17:18:11  __main__  INFO     DEINS: ('DINES', 'NIDES', 'SNIDE')\n",
            "2022/08/01-17:18:11  __main__  INFO     DEINT: ('TEIND', 'TINED')\n",
            "2022/08/01-17:18:11  __main__  INFO     DEIOS: ('EIDOS',)\n",
            "2022/08/01-17:18:11  __main__  INFO     DEIRS: ('DRIES', 'RESID', 'RIDES', 'SIRED')\n",
            "2022/08/01-17:18:11  __main__  INFO     DEIRT: ('TIRED', 'TRIED')\n",
            "2022/08/01-17:18:11  __main__  INFO     DEIST: ('DEIST', 'DIETS', 'DITES', 'EDITS', 'SITED', 'STIED', 'TIDES')\n",
            "2022/08/01-17:18:11  __main__  INFO     DENOR: ('DRONE', 'REDON')\n",
            "2022/08/01-17:18:11  __main__  INFO     DENOS: ('NODES', 'NOSED', 'SONDE')\n",
            "2022/08/01-17:18:11  __main__  INFO     DENOT: ('NOTED', 'TONED')\n",
            "2022/08/01-17:18:11  __main__  INFO     DENRS: ('NERDS', 'RENDS')\n",
            "2022/08/01-17:18:11  __main__  INFO     DENRT: ('TREND',)\n",
            "2022/08/01-17:18:11  __main__  INFO     DENST: ('DENTS', 'TENDS')\n",
            "2022/08/01-17:18:11  __main__  INFO     DEORS: ('DOERS', 'DOSER', 'REDOS', 'RESOD', 'ROSED')\n",
            "2022/08/01-17:18:11  __main__  INFO     DEORT: ('DOTER', 'TRODE')\n",
            "2022/08/01-17:18:11  __main__  INFO     DEOST: ('DOEST', 'DOTES')\n",
            "2022/08/01-17:18:11  __main__  INFO     DERST: ('DREST',)\n",
            "2022/08/01-17:18:11  __main__  INFO     DHINS: ('HINDS',)\n",
            "2022/08/01-17:18:11  __main__  INFO     DHIOT: ('DHOTI',)\n",
            "2022/08/01-17:18:11  __main__  INFO     DHIRT: ('THIRD',)\n",
            "2022/08/01-17:18:11  __main__  INFO     DINOT: ('TONDI',)\n",
            "2022/08/01-17:18:11  __main__  INFO     DINRS: ('RINDS',)\n",
            "2022/08/01-17:18:11  __main__  INFO     DINST: ('DINTS',)\n",
            "2022/08/01-17:18:11  __main__  INFO     DIORT: ('DROIT',)\n",
            "2022/08/01-17:18:11  __main__  INFO     DIOST: ('DOITS', 'ODIST')\n",
            "2022/08/01-17:18:11  __main__  INFO     DIRST: ('DIRTS', 'STRID')\n",
            "2022/08/01-17:18:11  __main__  INFO     EHINS: ('SHINE',)\n",
            "2022/08/01-17:18:11  __main__  INFO     EHINT: ('THEIN', 'THINE')\n",
            "2022/08/01-17:18:11  __main__  INFO     EHIOS: ('HOISE',)\n",
            "2022/08/01-17:18:11  __main__  INFO     EHIRS: ('HEIRS', 'HIRES', 'SHIER', 'SHIRE')\n",
            "2022/08/01-17:18:11  __main__  INFO     EHIRT: ('ITHER', 'THEIR')\n",
            "2022/08/01-17:18:11  __main__  INFO     EHIST: ('HEIST',)\n",
            "2022/08/01-17:18:11  __main__  INFO     EHNOR: ('HERON', 'HONER')\n",
            "2022/08/01-17:18:11  __main__  INFO     EHNOS: ('HONES', 'HOSEN', 'SHONE')\n",
            "2022/08/01-17:18:11  __main__  INFO     EHNRS: ('HERNS',)\n",
            "2022/08/01-17:18:11  __main__  INFO     EHNST: ('HENTS', 'SHENT', 'THENS')\n",
            "2022/08/01-17:18:11  __main__  INFO     EHORS: ('HEROS', 'HOERS', 'HORSE', 'SHOER', 'SHORE')\n",
            "2022/08/01-17:18:11  __main__  INFO     EHORT: ('OTHER', 'THROE')\n",
            "2022/08/01-17:18:11  __main__  INFO     EHOST: ('ETHOS', 'SHOTE', 'THOSE')\n",
            "2022/08/01-17:18:11  __main__  INFO     EINOR: ('IRONE',)\n",
            "2022/08/01-17:18:11  __main__  INFO     EINOS: ('EOSIN', 'NOISE')\n",
            "2022/08/01-17:18:11  __main__  INFO     EINRS: ('REINS', 'RESIN', 'RINSE', 'RISEN', 'SERIN', 'SIREN')\n",
            "2022/08/01-17:18:11  __main__  INFO     EINRT: ('INERT', 'INTER', 'NITER', 'NITRE', 'TRINE')\n",
            "2022/08/01-17:18:11  __main__  INFO     EINST: ('INSET', 'NEIST', 'SENTI', 'STEIN', 'TINES')\n",
            "2022/08/01-17:18:11  __main__  INFO     EIORS: ('OSIER',)\n",
            "2022/08/01-17:18:11  __main__  INFO     EIRST: ('RITES', 'TIERS', 'TIRES', 'TRIES')\n",
            "2022/08/01-17:18:11  __main__  INFO     ENORS: ('SENOR', 'SNORE')\n",
            "2022/08/01-17:18:11  __main__  INFO     ENORT: ('NOTER', 'TENOR', 'TONER', 'TRONE')\n",
            "2022/08/01-17:18:11  __main__  INFO     ENOST: ('NOTES', 'ONSET', 'SETON', 'STENO', 'STONE', 'TONES')\n",
            "2022/08/01-17:18:11  __main__  INFO     ENRST: ('NERTS', 'RENTS', 'STERN', 'TERNS')\n",
            "2022/08/01-17:18:11  __main__  INFO     EORST: ('ROSET', 'ROTES', 'STORE', 'TORES', 'TORSE')\n",
            "2022/08/01-17:18:11  __main__  INFO     HINOR: ('RHINO',)\n",
            "2022/08/01-17:18:11  __main__  INFO     HINST: ('HINTS', 'THINS')\n",
            "2022/08/01-17:18:11  __main__  INFO     HIOST: ('HOIST',)\n",
            "2022/08/01-17:18:11  __main__  INFO     HIRST: ('SHIRT',)\n",
            "2022/08/01-17:18:11  __main__  INFO     HNORS: ('HORNS', 'SHORN')\n",
            "2022/08/01-17:18:11  __main__  INFO     HNORT: ('NORTH', 'THORN')\n",
            "2022/08/01-17:18:11  __main__  INFO     HORST: ('HORST', 'SHORT')\n",
            "2022/08/01-17:18:11  __main__  INFO     INORS: ('IRONS', 'ORNIS', 'ROSIN')\n",
            "2022/08/01-17:18:11  __main__  INFO     INORT: ('INTRO', 'NITRO')\n",
            "2022/08/01-17:18:11  __main__  INFO     IORST: ('RIOTS', 'TIROS', 'TORSI', 'TRIOS', 'TROIS')\n",
            "2022/08/01-17:18:11  __main__  INFO     NORST: ('SNORT',)\n",
            "2022/08/01-17:18:11  __main__  INFO     guesses: 37 (first 37)\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('OATER', 'ORATE'), ('HINDS',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('DATES', 'SATED', 'STADE', 'STEAD', 'TSADE'), ('RHINO',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('DEATH', 'HATED'), ('IRONS', 'ORNIS', 'ROSIN'))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('NOTER', 'TENOR', 'TONER', 'TRONE'), ('DASHI',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('NOTED', 'TONED'), ('HAIRS',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('ETHOS', 'SHOTE', 'THOSE'), ('DINAR', 'DRAIN', 'NADIR', 'RANID'))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('DOETH',), ('AIRNS', 'NARIS', 'RAINS', 'RANIS', 'SARIN'))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('INSET', 'NEIST', 'SENTI', 'STEIN', 'TINES'), ('HOARD',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('THEIN', 'THINE'), ('DORSA', 'ROADS', 'SAROD'))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('TEIND', 'TINED'), ('HOARS', 'HORAS'))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('HEIST',), ('ADORN', 'RADON'))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('RITES', 'TIERS', 'TIRES', 'TRIES'), ('HONDA',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('ITHER', 'THEIR'), ('DONAS',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('HENTS', 'SHENT', 'THENS'), ('AROID', 'RADIO'))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('TREND',), ('OHIAS',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('AEONS',), ('THIRD',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('ANODE',), ('SHIRT',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('ADORE', 'OARED', 'OREAD'), ('HINTS', 'THINS'))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('AIDES', 'ASIDE', 'IDEAS'), ('NORTH', 'THORN'))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('ASHEN', 'HANSE'), ('DROIT',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('EARNS', 'NARES', 'NEARS', 'SANER', 'SNARE'), ('DHOTI',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('REDAN',), ('HOIST',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('HARES', 'HEARS', 'RHEAS', 'SHARE', 'SHEAR'), ('TONDI',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('ASHED', 'DEASH', 'HADES', 'HEADS', 'SADHE', 'SHADE'), ('INTRO', 'NITRO'))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('IRONE',), ('HADST',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('HONES', 'HOSEN', 'SHONE'), ('TRIAD',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('NODES', 'NOSED', 'SONDE'), ('AIRTH',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('HERON', 'HONER'), ('ADITS', 'DITAS', 'STAID', 'TSADI'))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('HONED',), ('AIRTS', 'ASTIR', 'SITAR', 'STAIR', 'STRIA', 'TARSI'))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('DRONE', 'REDON'), ('SAITH',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('HOSED', 'SHOED'), ('RIANT', 'TRAIN'))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('HORDE',), ('ANTIS', 'SAINT', 'SATIN', 'STAIN', 'TAINS'))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('SHINE',), ('TARDO',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('DINES', 'NIDES', 'SNIDE'), ('TORAH',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('DINER',), ('HOSTA', 'OATHS', 'SHOAT'))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('HIDES', 'SHIED'), ('TRONA',))\n",
            "2022/08/01-17:18:11  __main__  INFO     first 2 guess(es): (('SHEND',), ('RATIO',))\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin.env python3\n",
        "#\n",
        "# wordle.py\n",
        "#\n",
        "import itertools, math, optparse, os, sys, time\n",
        "# from log import log, log_path\n",
        "# from word import hasonly, musthave\n",
        "# from wordset import wordsfiles, wordssites\n",
        "\n",
        "1234567890123456789012345678901234567890123456789012345678901234567890\n",
        "\"\"\"\n",
        "Solution to the Wordle daily word puzzle.\n",
        "https://powerlanguage.co.uk/wordle/\n",
        "\"\"\"\n",
        "__all__ = [\"wordle\", ]\n",
        "__author__ = \"David C. Petty\"\n",
        "__copyright__ = \"Copyright 2022, David C. Petty\"\n",
        "__license__ = \"https://choosealicense.com/licenses/mit/\"\n",
        "__version__ = \"0.1.1\"\n",
        "__maintainer__ = \"David C. Petty\"\n",
        "__email__ = \"david_petty@psbma.org\"\n",
        "__status__ = \"Development\"\n",
        "\n",
        "logger = log(__name__)  # initialize logger\n",
        "\n",
        "comb = lambda n, k: math.factorial(n) // math.factorial(k) // math.factorial(n - k)\n",
        "\n",
        "def wordle(guess='     ', positions=0, length=5, number=2, extra=0):\n",
        "    \"\"\"Return list of wordle words words.\"\"\"\n",
        "    # Word-list files linked from:\n",
        "    # https://github.com/elasticdog/yawl\n",
        "\n",
        "    if '__file__' in globals():                         # not a Colab notebook\n",
        "        wordsdict = wordsfiles()                        # locally from files\n",
        "    #wordsdict = wordssites()                            # on-line from sites\n",
        "\n",
        "    # words is the union of all words-sets.\n",
        "    #words = set.union(*wordsdict.values())\n",
        "    words = words_as_sets()\n",
        "    frequent = 'ETAOINSHRDLUCMFWYGPBVKQJXZ'.upper()\n",
        "    word_map, guesses = dict(), tuple()\n",
        "\n",
        "    # Create word_map of length-letter words mapped to their letters.\n",
        "    total, group_scale, guess_scale = length * number + extra, 70, 510000\n",
        "    logger.info(f\"{comb(total, length)} combinations of {length} letters out of the {total} most common: '{frequent[: total]}'... (~{comb(total, length) // group_scale}s)\")\n",
        "    start_t = time.time()                               # start time\n",
        "\n",
        "    possibilities = itertools.combinations(frequent[: total], length)\n",
        "    for letters in possibilities:\n",
        "        for word in words:\n",
        "            if len(word) == length and musthave(word, letters):\n",
        "                key = ''.join(sorted(letters))\n",
        "                word_map[key] = word_map.get(key, tuple()) + (word, )\n",
        "    logger.info(f\"groups with words: ({','.join(sorted(word_map))})\")\n",
        "    groups_t = time.time()                              # group time\n",
        "    logger.info(f\"time: {round(groups_t - start_t, 1)}s\")\n",
        "\n",
        "    if len(word_map) < number: return word_map, guesses\n",
        "\n",
        "    # TODO: make interactive and iterative\n",
        "    # Print best number words to guess.\n",
        "    logger.info(f\"{comb(len(word_map), number)} combinations of {number} group(s) out of the {len(word_map)} with words... (~{comb(len(word_map), number) // guess_scale}s)\")\n",
        "    guesses = tuple( ( word_map[k] for k in key )\n",
        "        for key in ( x for x in itertools.combinations(word_map, number ) \n",
        "            if all( hasnone(*t) for t in itertools.combinations(x, 2) ) ) )\n",
        "    guess_t = time.time()\n",
        "    logger.info(f\"time: {round(guess_t - groups_t, 1)}s\")\n",
        "\n",
        "    sorted_word_map = { k: tuple(sorted(v)) for k, v in word_map.items() }\n",
        "    sorted_guesses = tuple( tuple( tuple(sorted(t)) for t in g ) for g in guesses )\n",
        "\n",
        "    return sorted_word_map, sorted_guesses\n",
        "\n",
        "# TODO: fix spacing\n",
        "# TODO: change to argparse\n",
        "class WordleOptionParser( optparse.OptionParser ):\n",
        "    def __init__( self, **kwargs ):\n",
        "        optparse.OptionParser.__init__( self, **kwargs )\n",
        "        self.remove_option( \"-h\" )\n",
        "        self.add_option( \"-?\", \"--help\", action=\"help\",\n",
        "            help=\"show this help message and exit\" )\n",
        "    def error( self, msg ):\n",
        "        name = self.get_prog_name( )\n",
        "        sys.stderr.write( \"{name}: error: {msg}\\n\\n\".format( **locals( ) ) )\n",
        "        self.print_help( )\n",
        "        sys.exit( 2 )\n",
        "\n",
        "def test( argv ):\n",
        "    import logging\n",
        "    # TODO: fix this\n",
        "    # Parse command-line options.\n",
        "    usage = \"usage: %prog {LETTERS | -i} [-l L] [-? -v]\"\n",
        "    description = \"Find spelling-bee words using LETTERS and including LETTERS[0].\"\n",
        "    parser = WordleOptionParser( usage=usage, description=description, version=__version__ )\n",
        "    parser.add_option( \"-i\", \"--input\",\n",
        "        action=\"store_true\", dest=\"i\", default=False,\n",
        "        help=\"input LETTERS from keyboard? [%default]\" )\n",
        "    parser.add_option( \"-l\", \"--length\",\n",
        "        action=\"store\", type='int', dest=\"l\", default=5,\n",
        "        help=\"words of length >= L [%default]\" )\n",
        "    parser.add_option( \"-v\", \"--verbose\",\n",
        "        action=\"store_true\", dest=\"verbose\", default=False,\n",
        "        help=\"log status information while processing [%default]\" )\n",
        "    opts, args = parser.parse_args( args=argv[ 1: ] )\n",
        "    # Process command-line options.\n",
        "    len_args = 0 if opts.i else 1\n",
        "    if len( args ) != len_args:\n",
        "        error = f\"too {'few' if len(args) < len_args else 'many'} arguments\"\n",
        "        parser.error( error )\n",
        "    letters, = args if not opts.i else (input('Wordle letters: '),)\n",
        "    if not opts.verbose: logging.disable(logging.INFO)\n",
        "    logger.info(f\"python3 {' '.join(argv)}\")\n",
        "    logger.info(f\"LOG PATH: {log_path()}\")\n",
        "\n",
        "    # Solve Wordle.\n",
        "    number, extra = 2, 0\n",
        "    words, guesses = wordle(number=number, extra=extra)\n",
        "    logger.info(f\"{len(words)} groups with words; {len(guesses)} guesses of length {number};\")\n",
        "    # Log first results.\n",
        "    fw, fg = min(len(words), 5000 - 20), min(len(guesses), 5000 - 20 - len(words))\n",
        "    logger.info(f\"words: {len(words)} (first {min(len(words), fw)})\")\n",
        "    st2st = lambda ws: tuple(sorted(''.join(s) for s in ws))    # already sorted?\n",
        "    for key in sorted(words)[: fw]:\n",
        "        logger.info(f\"{key}: {st2st(words[key])}\")\n",
        "    logger.info(f\"guesses: {len(guesses)} (first {min(len(guesses), fg)})\")\n",
        "    for guess in guesses[: fg]:\n",
        "        logger.info(f\"first {len(guess)} guess(es): {tuple( st2st(g) for g in guess )}\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    is_idle, is_pycharm, is_jupyter = (\n",
        "        'idlelib' in sys.modules,\n",
        "        int(os.getenv('PYCHARM', 0)),\n",
        "        '__file__' not in globals()\n",
        "        )\n",
        "    if any((is_idle, is_pycharm, is_jupyter, )):\n",
        "        # Collab Jupyter Notebook\n",
        "        test([sys.argv[0], '-v', 'NOTHING', ])\n",
        "    else:\n",
        "        test(sys.argv)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "wordle.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}